{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66adb498",
   "metadata": {},
   "source": [
    "## 步骤一：数据准备\n",
    "首先，我们需要导入一些必要的Python库来处理图像数据和构建模型。以下是导入的库：\n",
    "\n",
    "我们使用glob库来获取文件路径，numpy用于数值计算，pandas用于数据处理，nibabel用于加载和处理医学图像数据，OrthoSlicer3D用于图像可视化，Counter用于计数统计。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa94695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob                # 获取文件路径\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib      # 处理医学图像数据\n",
    "from nibabel.viewers import OrthoSlicer3D    # 图像可视化\n",
    "from collections import Counter              # 计数统计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec8b1f",
   "metadata": {},
   "source": [
    "## 步骤二：数据预处理\n",
    "接下来，我们将读取训练集和测试集的文件路径，并对它们进行随机打乱，以保证数据的随机性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c41ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集文件路径\n",
    "train_path = glob.glob('./脑PET图像分析和疾病预测挑战赛公开数据/Train/*/*')\n",
    "test_path = glob.glob('./脑PET图像分析和疾病预测挑战赛公开数据/Test/*')\n",
    "\n",
    "# 打乱训练集和测试集的顺序\n",
    "np.random.shuffle(train_path)\n",
    "np.random.shuffle(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be49714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\25.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\10.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\9.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\10.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\22.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\19.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\17.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\19.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\12.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\24.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\7.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\15.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\6.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\3.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\12.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\9.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\23.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\4.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\17.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\18.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\3.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\5.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\11.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\1.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\7.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\24.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\1.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\18.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\21.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\13.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\20.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\4.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\6.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\21.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\16.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\2.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\8.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\13.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\14.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\23.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\15.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\5.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\8.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\2.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\25.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\NC\\\\11.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\14.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\16.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\20.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Train\\\\MCI\\\\22.nii']\n",
      "['./脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\44.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\67.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\8.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\75.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\66.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\2.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\59.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\80.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\3.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\97.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\62.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\34.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\42.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\45.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\43.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\37.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\41.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\36.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\33.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\99.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\57.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\56.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\23.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\84.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\20.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\86.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\98.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\76.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\29.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\18.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\9.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\7.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\85.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\48.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\38.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\61.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\72.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\70.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\68.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\22.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\24.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\94.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\25.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\17.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\16.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\39.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\31.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\46.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\89.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\11.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\93.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\40.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\64.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\51.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\19.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\5.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\60.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\63.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\30.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\32.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\54.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\35.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\81.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\69.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\79.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\55.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\88.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\26.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\90.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\53.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\50.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\82.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\71.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\96.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\6.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\28.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\65.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\4.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\12.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\27.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\21.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\92.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\15.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\47.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\78.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\13.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\10.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\83.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\58.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\74.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\77.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\95.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\87.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\91.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\52.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\1.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\100.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\73.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\49.nii', './脑PET图像分析和疾病预测挑战赛公开数据/Test\\\\14.nii']\n"
     ]
    }
   ],
   "source": [
    "print(train_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92582516",
   "metadata": {},
   "source": [
    "## 步骤三：特征提取\n",
    "对于深度学习任务，特征提取是非常重要的一步。在本例中，我们定义了一个函数extract_feature，用于从脑PET图像中提取特征。\n",
    "\n",
    "extract_feature函数从文件路径加载PET图像数据，并从中随机选择10个通道。然后，它计算了一系列统计特征，如非零像素数量、零像素数量、平均值、标准差等。最后，函数根据文件路径判断样本类别，并将提取到的特征和类别作为返回值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccdf7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(path):\n",
    "    # 加载PET图像数据\n",
    "    img = nib.load(path)\n",
    "    # 获取第一个通道的数据\n",
    "    img = img.dataobj[:, :, :, 0]\n",
    "    \n",
    "    # 随机筛选其中的10个通道提取特征\n",
    "    random_img = img[:, :, np.random.choice(range(img.shape[2]), 10)]\n",
    "    \n",
    "    # 对图片计算统计值\n",
    "    feat = [\n",
    "        (random_img != 0).sum(),               # 非零像素的数量\n",
    "        (random_img == 0).sum(),               # 零像素的数量\n",
    "        random_img.mean(),                     # 平均值\n",
    "        random_img.std(),                      # 标准差\n",
    "        len(np.where(random_img.mean(0))[0]),  # 在列方向上平均值不为零的数量\n",
    "        len(np.where(random_img.mean(1))[0]),  # 在行方向上平均值不为零的数量\n",
    "        random_img.mean(0).max(),              # 列方向上的最大平均值\n",
    "        random_img.mean(1).max()               # 行方向上的最大平均值\n",
    "    ]\n",
    "    \n",
    "    # 根据路径判断样本类别（'NC'表示正常，'MCI'表示异常）\n",
    "    if 'NC' in path:\n",
    "        return feat + ['NC']\n",
    "    else:\n",
    "        return feat + ['MCI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3518cf",
   "metadata": {},
   "source": [
    "## 步骤四：模型训练\n",
    "在这一步骤中，我们将利用extract_feature函数提取训练集和测试集的特征，并使用逻辑回归模型对训练集进行训练。\n",
    "\n",
    "在这里，我们通过循环将特征提取过程重复进行30次，这是为了增加训练样本的多样性。然后，我们使用逻辑回归模型LogisticRegression来训练数据。在训练完成后，模型已经学习到了从特征到类别的映射关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188dd963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对训练集进行30次特征提取，每次提取后的特征以及类别（'NC'表示正常，'MCI'表示异常）被添加到train_feat列表中。\n",
    "train_feat = []\n",
    "for _ in range(30):\n",
    "    for path in train_path:\n",
    "        train_feat.append(extract_feature(path))\n",
    "     \n",
    "# 对测试集进行30次特征提取   \n",
    "test_feat = []\n",
    "for _ in range(30):\n",
    "    for path in test_path:\n",
    "        test_feat.append(extract_feature(path))\n",
    "        \n",
    "# 使用训练集的特征作为输入，训练集的类别作为输出，对逻辑回归模型进行训练。\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression(max_iter=1000)\n",
    "m.fit(\n",
    "    np.array(train_feat)[:, :-1].astype(np.float32),  # 特征\n",
    "    np.array(train_feat)[:, -1]                       # 类别\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce19afb2",
   "metadata": {},
   "source": [
    "在scikit-learn（sklearn）中，除了逻辑回归（Logistic Regression）之外，还有许多其他的机器学习模型可以用于分类任务中，以下是一些常用于分类任务的机器学习模型：\n",
    "\n",
    "支持向量机（Support Vector Machines，SVM）：用于二分类和多分类问题，通过构建一个超平面来区分不同类别的样本。\n",
    "决策树（Decision Trees）：适用于二分类和多分类问题，通过对特征空间进行划分来分类样本。\n",
    "随机森林（Random Forests）：基于多个决策树的集成算法，用于二分类和多分类问题，提高了模型的泛化能力。\n",
    "K最近邻算法（K-Nearest Neighbors，KNN）：根据最近邻样本的类别来分类新样本，适用于二分类和多分类问题。\n",
    "朴素贝叶斯（Naive Bayes）：基于贝叶斯定理的分类方法，适用于文本分类等问题。\n",
    "多层感知器（Multi-layer Perceptrons，MLP）：一种人工神经网络，用于解决复杂的分类问题。\n",
    "卷积神经网络（Convolutional Neural Networks，CNN）：专用于处理图像和视觉数据的神经网络，在图像分类任务中表现出色。\n",
    "这些模型在分类任务中有不同的应用场景和性能表现，取决于数据集的特征、样本数量和问题的复杂性。在实际应用中，通常需要根据数据集的特点和具体任务来选择合适的分类模型，并进行模型调参和性能评估，以达到最佳的分类效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764bb58",
   "metadata": {},
   "source": [
    "## 步骤五：预测与结果提交\n",
    "在这一步骤中，我们使用训练好的逻辑回归模型对测试集进行预测，并将预测结果进行投票，选出最多的类别作为该样本的最终预测类别。最后，我们将预测结果存储在CSV文件中并提交结果。\n",
    "\n",
    "具体来说，我们使用了Counter来统计每个样本的30次预测结果中最多的类别，并将结果存储在test_pred_label列表中。然后，我们将样本ID和对应的预测类别存储在一个DataFrame中，并将其按照ID排序后保存为CSV文件，这样我们就得到了最终的结果提交文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d524916",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Test\\\\44'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m test_pred_label \u001b[38;5;241m=\u001b[39m [Counter(x)\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m test_pred]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 生成提交结果的DataFrame，其中包括样本ID和预测类别。\u001b[39;00m\n\u001b[0;32m     10\u001b[0m submit \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     11\u001b[0m     {\n\u001b[1;32m---> 12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m test_path],  \u001b[38;5;66;03m# 提取测试集文件名中的ID\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m#'uuid': [int(os.path.splitext(os.path.basename(x))[0]) for x in test_path],\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: test_pred_label                                  \u001b[38;5;66;03m# 预测的类别\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     }\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 按照ID对结果排序并保存为CSV文件\u001b[39;00m\n\u001b[0;32m     19\u001b[0m submit \u001b[38;5;241m=\u001b[39m submit\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m test_pred_label \u001b[38;5;241m=\u001b[39m [Counter(x)\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m test_pred]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 生成提交结果的DataFrame，其中包括样本ID和预测类别。\u001b[39;00m\n\u001b[0;32m     10\u001b[0m submit \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     11\u001b[0m     {\n\u001b[1;32m---> 12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m test_path],  \u001b[38;5;66;03m# 提取测试集文件名中的ID\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m#'uuid': [int(os.path.splitext(os.path.basename(x))[0]) for x in test_path],\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: test_pred_label                                  \u001b[38;5;66;03m# 预测的类别\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     }\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 按照ID对结果排序并保存为CSV文件\u001b[39;00m\n\u001b[0;32m     19\u001b[0m submit \u001b[38;5;241m=\u001b[39m submit\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Test\\\\44'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 对测试集进行预测并进行转置操作，使得每个样本有30次预测结果。\n",
    "test_pred = m.predict(np.array(test_feat)[:, :-1].astype(np.float32))\n",
    "test_pred = test_pred.reshape(30, -1).T\n",
    "\n",
    "# 对每个样本的30次预测结果进行投票，选出最多的类别作为该样本的最终预测类别，存储在test_pred_label列表中。\n",
    "test_pred_label = [Counter(x).most_common(1)[0][0] for x in test_pred]\n",
    "\n",
    "# 生成提交结果的DataFrame，其中包括样本ID和预测类别。\n",
    "submit = pd.DataFrame(\n",
    "    {\n",
    "        'uuid': [int(x.split('/')[-1][:-4]) for x in test_path],  # 提取测试集文件名中的ID\n",
    "        #'uuid': [int(os.path.splitext(os.path.basename(x))[0]) for x in test_path],\n",
    "        'label': test_pred_label                                  # 预测的类别\n",
    "    }\n",
    ")\n",
    "\n",
    "# 按照ID对结果排序并保存为CSV文件\n",
    "submit = submit.sort_values(by='uuid')\n",
    "submit.to_csv('submit.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a4303a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78,\n",
       " 92,\n",
       " 80,\n",
       " 77,\n",
       " 17,\n",
       " 12,\n",
       " 28,\n",
       " 4,\n",
       " 39,\n",
       " 23,\n",
       " 7,\n",
       " 55,\n",
       " 31,\n",
       " 14,\n",
       " 29,\n",
       " 65,\n",
       " 73,\n",
       " 1,\n",
       " 47,\n",
       " 98,\n",
       " 6,\n",
       " 38,\n",
       " 22,\n",
       " 35,\n",
       " 36,\n",
       " 58,\n",
       " 19,\n",
       " 91,\n",
       " 82,\n",
       " 61,\n",
       " 85,\n",
       " 59,\n",
       " 50,\n",
       " 56,\n",
       " 75,\n",
       " 48,\n",
       " 5,\n",
       " 20,\n",
       " 96,\n",
       " 53,\n",
       " 60,\n",
       " 66,\n",
       " 21,\n",
       " 74,\n",
       " 34,\n",
       " 93,\n",
       " 9,\n",
       " 64,\n",
       " 24,\n",
       " 54,\n",
       " 42,\n",
       " 26,\n",
       " 43,\n",
       " 10,\n",
       " 27,\n",
       " 63,\n",
       " 3,\n",
       " 46,\n",
       " 41,\n",
       " 79,\n",
       " 88,\n",
       " 76,\n",
       " 51,\n",
       " 13,\n",
       " 16,\n",
       " 100,\n",
       " 40,\n",
       " 72,\n",
       " 95,\n",
       " 8,\n",
       " 86,\n",
       " 62,\n",
       " 67,\n",
       " 33,\n",
       " 37,\n",
       " 49,\n",
       " 15,\n",
       " 81,\n",
       " 32,\n",
       " 83,\n",
       " 89,\n",
       " 90,\n",
       " 44,\n",
       " 25,\n",
       " 45,\n",
       " 71,\n",
       " 69,\n",
       " 97,\n",
       " 57,\n",
       " 94,\n",
       " 68,\n",
       " 99,\n",
       " 18,\n",
       " 30,\n",
       " 52,\n",
       " 11,\n",
       " 2,\n",
       " 84,\n",
       " 70,\n",
       " 87]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "[int(os.path.splitext(os.path.basename(x))[0]) for x in test_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8c4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
