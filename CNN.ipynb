{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33f222f",
   "metadata": {},
   "source": [
    "# 1.加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855374b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)#随机数生成器的种子设置为0\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel.viewers import OrthoSlicer3D\n",
    "\n",
    "# 加载数据文件\n",
    "train_path = glob.glob('./脑PET图像分析和疾病预测挑战赛公开数据/Train/*/*')\n",
    "test_path = glob.glob('./脑PET图像分析和疾病预测挑战赛公开数据/Test/*')\n",
    "\n",
    "# 打乱文件顺序\n",
    "np.random.shuffle(train_path)\n",
    "np.random.shuffle(test_path)\n",
    "\n",
    "DATA_CACHE = {}\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "            \n",
    "    #预处理图像与获得标签\n",
    "    def __getitem__(self, index):\n",
    "        if self.img_path[index] in DATA_CACHE:\n",
    "            img = DATA_CACHE[self.img_path[index]]\n",
    "        else:\n",
    "            img = nib.load(self.img_path[index]) \n",
    "            img = img.dataobj[:,:,:, 0]# 去除第4维\n",
    "            DATA_CACHE[self.img_path[index]] = img\n",
    "        \n",
    "        # 随机选择一些通道（60）            \n",
    "        idx = np.random.choice(range(img.shape[-1]), 60)\n",
    "        img = img[:, :, idx]\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image = img)['image']\n",
    "        \n",
    "        img = img.transpose([2,0,1]) # 转成resnet输入所需\n",
    "        return img,torch.from_numpy(np.array(int('NC' in self.img_path[index])))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "# 图像增强\n",
    "import albumentations as A\n",
    "transform  = A.Compose([\n",
    "             A.RandomRotate90(),\n",
    "             A.RandomCrop(128, 128),\n",
    "             A.HorizontalFlip(p=0.5),\n",
    "             A.RandomBrightnessContrast(p=0.5),\n",
    "         ])\n",
    "\n",
    "# 加载数据集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[:-10],transform), batch_size=20, shuffle=True, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[-10:],transform), batch_size=20, shuffle=False, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(test_path,transform), batch_size=20, shuffle=False, num_workers=0, pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df1b0c",
   "metadata": {},
   "source": [
    "# 2.定义CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460713aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\CC/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cf4d49b1794bd48897383b9bea9d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "class XunFeiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet, self).__init__()\n",
    "        \n",
    "        # resnet18        \n",
    "        model = models.resnet34(True)\n",
    "        model.conv1 = torch.nn.Conv2d(60, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=True)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(512, 2)\n",
    "\n",
    "#         # resnet50\n",
    "#         model = models.resnet50(True)\n",
    "#         # 初始卷积层 输入通道60 输出通道64，卷积核7*7，步长2,2，填充3*3\n",
    "#         model.conv1 = torch.nn.Conv2d(60, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=True)\n",
    "#         # 平均池化层替换为⾃适应平均池化层，1-*1\n",
    "#         model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "#         # 全连接层替换为线性层，输⼊维度为 2048，输出维度为2（NC,MCI）\n",
    "#         model.fc = nn.Linear(2048, 2)\n",
    "\n",
    "        self.resnet = model\n",
    "        \n",
    "    # 前向传递    \n",
    "    def forward(self, img):        \n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "        \n",
    "model = XunFeiNet()\n",
    "model = model.to('cuda')\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "# 梯度下降方法\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff25a8",
   "metadata": {},
   "source": [
    "# 3.模型训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39315676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "lossitem:0.8414594531059265\n",
      "loss:0.8635172247886658,train_acc:0.4,val_acc:0.3\n",
      "epoch:1\n",
      "lossitem:0.6841958165168762\n",
      "loss:0.6712139546871185,train_acc:0.525,val_acc:0.4\n",
      "epoch:2\n",
      "lossitem:0.769984245300293\n",
      "loss:0.6631583571434021,train_acc:0.525,val_acc:0.4\n",
      "epoch:3\n",
      "lossitem:0.6631976962089539\n",
      "loss:0.7890571057796478,train_acc:0.525,val_acc:0.6\n",
      "epoch:4\n",
      "lossitem:0.6975802779197693\n",
      "loss:0.7957723438739777,train_acc:0.6,val_acc:0.5\n",
      "epoch:5\n",
      "lossitem:0.8171712160110474\n",
      "loss:0.7364800572395325,train_acc:0.45,val_acc:0.4\n",
      "epoch:6\n",
      "lossitem:0.7349840998649597\n",
      "loss:0.7277774512767792,train_acc:0.475,val_acc:0.6\n",
      "epoch:7\n",
      "lossitem:0.9711660146713257\n",
      "loss:0.7848738431930542,train_acc:0.45,val_acc:0.7\n",
      "epoch:8\n",
      "lossitem:0.6836105585098267\n",
      "loss:0.7349509000778198,train_acc:0.6,val_acc:0.8\n",
      "epoch:9\n",
      "lossitem:0.7610410451889038\n",
      "loss:0.7161563634872437,train_acc:0.575,val_acc:0.6\n",
      "epoch:10\n",
      "lossitem:0.8892093896865845\n",
      "loss:0.850201427936554,train_acc:0.725,val_acc:0.4\n",
      "epoch:11\n",
      "lossitem:0.7102230787277222\n",
      "loss:0.6557908654212952,train_acc:0.625,val_acc:0.5\n",
      "epoch:12\n",
      "lossitem:0.5647556781768799\n",
      "loss:0.5710200071334839,train_acc:0.55,val_acc:0.4\n",
      "epoch:13\n",
      "lossitem:0.6419917941093445\n",
      "loss:0.5910941660404205,train_acc:0.55,val_acc:0.4\n",
      "epoch:14\n",
      "lossitem:0.6407312154769897\n",
      "loss:0.6107585430145264,train_acc:0.55,val_acc:0.5\n",
      "epoch:15\n",
      "lossitem:0.6669437289237976\n",
      "loss:0.695843368768692,train_acc:0.575,val_acc:0.4\n",
      "epoch:16\n",
      "lossitem:0.7441612482070923\n",
      "loss:0.6866654753684998,train_acc:0.6,val_acc:0.5\n",
      "epoch:17\n",
      "lossitem:0.5936179161071777\n",
      "loss:0.5826012790203094,train_acc:0.55,val_acc:0.9\n",
      "epoch:18\n",
      "lossitem:0.6814209222793579\n",
      "loss:0.7176211178302765,train_acc:0.625,val_acc:0.5\n",
      "epoch:19\n",
      "lossitem:0.7009938359260559\n",
      "loss:0.6008176505565643,train_acc:0.725,val_acc:0.7\n",
      "epoch:20\n",
      "lossitem:0.5707618594169617\n",
      "loss:0.7050488293170929,train_acc:0.575,val_acc:0.7\n",
      "epoch:21\n",
      "lossitem:0.5701309442520142\n",
      "loss:0.5960586667060852,train_acc:0.625,val_acc:0.6\n",
      "epoch:22\n",
      "lossitem:0.7763711810112\n",
      "loss:0.6962879002094269,train_acc:0.575,val_acc:0.4\n",
      "epoch:23\n",
      "lossitem:0.5798858404159546\n",
      "loss:0.5408797562122345,train_acc:0.6,val_acc:0.6\n",
      "epoch:24\n",
      "lossitem:0.5852161645889282\n",
      "loss:0.5071471631526947,train_acc:0.7,val_acc:0.7\n",
      "epoch:25\n",
      "lossitem:0.5770880579948425\n",
      "loss:0.6650364100933075,train_acc:0.575,val_acc:0.7\n",
      "epoch:26\n",
      "lossitem:0.6314409971237183\n",
      "loss:0.5577979236841202,train_acc:0.625,val_acc:0.5\n",
      "epoch:27\n",
      "lossitem:0.5981709957122803\n",
      "loss:0.7206098735332489,train_acc:0.7,val_acc:0.6\n",
      "epoch:28\n",
      "lossitem:0.5109072923660278\n",
      "loss:0.5342550277709961,train_acc:0.575,val_acc:0.9\n",
      "epoch:29\n",
      "lossitem:0.605474054813385\n",
      "loss:0.6137483417987823,train_acc:0.75,val_acc:0.8\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    # 模型设置为训练模式\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # 将训练集输入网络并得到当前结果\n",
    "        input = input.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        output = model(input)\n",
    "        # 计算损失\n",
    "        loss = criterion(output, target.long())\n",
    "        \n",
    "        # 去除梯度\n",
    "        optimizer.zero_grad()\n",
    "        # \n",
    "        loss.backward()\n",
    "        # 更新模型参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 20 次输出一次损失值\n",
    "        if i % 20 == 0:\n",
    "            print(f\"lossitem:{loss.item()}\")\n",
    "            \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    return train_loss/len(train_loader)\n",
    "            \n",
    "def validate(val_loader, model, criterion):\n",
    "    # 模型设置为验证模式\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    # 禁⽤梯度计算，提⾼计算速度\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            # 将验证集输入网络并得到当前结果\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            target = target.long()\n",
    "            # 计算损失\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # 判断模型输出是否与真实值相等\n",
    "            val_acc += (output.argmax(1) == target).sum().item()\n",
    "            \n",
    "    return val_acc / len(val_loader.dataset)\n",
    "    \n",
    "for num in range(100):\n",
    "    print(f\"epoch:{num}\")\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc  = validate(val_loader, model, criterion)\n",
    "    train_acc = validate(train_loader, model, criterion)\n",
    "    \n",
    "    print(f\"loss:{train_loss},train_acc:{train_acc},val_acc:{val_acc}\")\n",
    "    if train_acc*0.5+val_acc*0.5> 0.8&& train_loss<0.5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0906499",
   "metadata": {},
   "source": [
    "# 4.模型预测与提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c344be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_loader, model, criterion):\n",
    "    # 模型设置为验证模式\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        # i =num/batchsize\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            input = input.cuda()# torch.Size([20, 60, 120, 120])[bs,3d,width,height]\n",
    "            target = target.cuda()# torch.Size([20])\n",
    "            output = model(input)# [20,2][bs,2]\n",
    "            \n",
    "            test_pred.append(output.data.cpu().numpy())# [100,2]\n",
    "            \n",
    "    return np.vstack(test_pred)\n",
    "\n",
    "# 预测\n",
    "pred = None\n",
    "for _ in range(10):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model, criterion)\n",
    "    else:\n",
    "        pred += predict(test_loader, model, criterion)\n",
    "        \n",
    "        \n",
    "# 保存为csv文件\n",
    "submit = pd.DataFrame(\n",
    "    {\n",
    "        'uuid': [int(x.split('\\\\')[-1][:-4]) for x in test_path],\n",
    "        'label': pred.argmax(1)# 寻找最大值的index\n",
    "})\n",
    "# label中的1转换为NC，0转换为MCI\n",
    "submit['label'] = submit['label'].map({1:'NC', 0: 'MCI'})\n",
    "# 根据uuid进行升序排列\n",
    "submit = submit.sort_values(by='uuid')\n",
    "submit.to_csv('submit2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eed613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
